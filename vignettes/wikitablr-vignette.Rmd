---
title: "wikitablr Vignette"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{my-vignette}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  eval = FALSE,
  comment = "#>"
)
```

```{r setup, include=FALSE}
library(wikitablr)
library(dplyr)
library(purrr)
library(stringr)
```

The primary goal of the`wikitablr`package is to facilitate the process of working with data from wikipedia tables in R. The functions in this package allow the user to read in all tables on a wikipedia page given a url, and then apply specific cleaning functions to individual tables, subsets of tables, or all of the tables.

## Reading in Tables

For this vignette we will be use the wikipedia page of [Bob's Burgers episodes]("https://en.wikipedia.org/wiki/List_of_Bob%27s_Burgers_episodes"). 

The `read_wikitables()`function takes in a wikipedia url and outputs a data table with each row corresponding to one table on the wikipedia page. The tables themselves are stored in the 'table' column. The other columns provide additional information about each table including the table number, the time retrieved, and the storage space each table takes up. 
```{r}
bobs_burgers <- read_wikitables("https://en.wikipedia.org/wiki/List_of_Bob%27s_Burgers_episodes")
bobs_burgers
```
## Cleaning Functions

Each cleaning function takes in an individual table and outputs a modified table. We can apply the cleaning functions to an individual table by first extracting the table, or we can map the cleaning functions over a list of tables.

#### Clean column names

`clean_wiki_names()` cleans the column names of a dataframe; it removes footnotes and special characters, and converts letter cases. `clean_wiki_names()` utilizes the functionality of `janitor::clean_names()` and can convert to any case (default is snake_case).

If we want to work with one table individually, we can extract it and then apply `clean_wiki_names()`. For example, if we want to clean the names of the 11th table on the Bob's Burgers page, it will look like this.

```{r}
# extract table 11
episodes <- bobs_burgers %>%
   pull(table) %>%
   pluck(11) 
episodes
```
```{r}
# clean names
episodes_clean <- clean_wiki_names(episodes)
episodes_clean
```

If we want to clean the names of all of the tables that list episodes in a season, we could do so by mapping `clean_wiki_names()` over all of the tables. This will output a table with an added column `clean_table` that contains the modified tables with clean names.
```{r}
# filter only tables that contain episodes
episode_list <- bobs_burgers %>%
  filter(stringr::str_detect(class, "wikiepisodetable"))

# map clean_wiki_names() over all tables
episode_list %>%
  mutate(clean_table = map(table, clean_wiki_names))
```

```{r}
episode_list %>%
  mutate(
    clean_table = table %>%
      map(clean_wiki_names) %>%
      map(special_to_na)
  )
```


#### Add NAs to data

`empty_to_na()` takes blank cells, solitary special characters, and any designated string, and converts them to `NA`. This can be utilized on the table for Bob's Burgers' current season, which has some "TBA" and "TBD" values for unreleased episodes. Using `empty_to_na()` we can convert these to `r NA`:

```{r}
# not sure which table has "TBA" and "TBD"
episodes <- empty_to_na(episodes, to_na = c("TBA", "TBD"))

tail(episodes, 3)
```

#### Remove footnotes

`remove_footnotes()` does just that! Wikipedia's footnotes are contained within brackets ([ ]), so this function removes anything contained in brackets (as well as the brackets themselves) from the data.

```{r}
episodes <- remove_footnotes(episodes)

head(episodes, 3)
```

#### Convert data types

`wikitablr` also does some initial parsing of data types. `convert_type()` can detect if a column is likely Date or numeric, and re-codes it as such:

```{r}
str(convert_types(episodes))
```

As can be seen, this function isn't perfect, and the original_air_date column was parsed into character, rather than Date. A situation like this calls for some manual data-cleaning:

```{r}
# error
#using stringr to remove the duplicate date in parentheses
episodes$original_air_date <- stringr::str_remove(episodes$original_air_date, "\\(.*\\)") %>% stringr::str_trim()

str(convert_types(episodes))
```

Now `convert_type()` correctly recodes original_air_date as Date!

#### Remove unnecessary rows

`wikitablr`'s final function, `clean_rows()` removes unnecessary rows: those that are duplicates of the header, and those that have the same value for every column (seen when the Wikipedia table has a banner in the middle).

Here is an example using the first table on the Bob's Burgers wikipedia page.

```{r}
table1 <- bobs_burgers %>%
   pull(table) %>%
   pluck(1)
table1
```
```{r}
clean_rows(table1)
```


